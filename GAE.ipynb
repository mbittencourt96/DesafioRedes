{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os grafos e csv necessários e bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import random\n",
    "from torch_geometric.nn import GAE, GCNConv\n",
    "import torch.nn as nn\n",
    "from torch import nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch.optim as optim\n",
    "import torch \n",
    "from torch_geometric import seed_everything\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "G = nx.read_gml('GraphMissingEdges.gml')\n",
    "\n",
    "edges_to_evaluate = pd.read_csv('edgesToEvaluate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(69)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "categories = pd.read_csv('categories.csv', index_col='CategoryId')\n",
    "num_categorias = len(categories)\n",
    "\n",
    "def bag_of_words(categories_list):\n",
    "    # print(categories_list)\n",
    "    categorias = categories_list.split(',')\n",
    "    bag = np.zeros(num_categorias, dtype=np.float32)\n",
    "\n",
    "    for i, categoria in enumerate(categorias):\n",
    "        try:\n",
    "            bag[i] = 1\n",
    "        except IndexError:\n",
    "            pass\n",
    "    return bag\n",
    "\n",
    "G_pyg = G.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dataset a partir do grafo do desafio\n",
    "# Aqui definimos os parametros que serão relevantes (rating, reviewCount e categories)\n",
    "\n",
    "key_to_index = {}\n",
    "for index, (n, data) in enumerate(G_pyg.nodes.data()):\n",
    "    key_to_index[n] = index\n",
    "    G_pyg.nodes[n]['stars'] = np.array([float(data['stars'])])\n",
    "    G_pyg.nodes[n]['reviewCount'] = np.array([float(data['reviewCount'])])\n",
    "    G_pyg.nodes[n]['categories'] = bag_of_words(data['categories'])\n",
    "\n",
    "dataset = from_networkx(G_pyg, group_edge_attrs=all,group_node_attrs=['categories','reviewCount','stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da GAE de duas camadas, ativação com Relu na GCN, otimizador Adam, learning rate = 0.001 e 100 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index - representa a conectividade do grafo no formato [2, num_edges]\n",
    "# edge_attr - matriz de features de aresta com o formato [num_edges, num_edges_features]\n",
    "\n",
    "# parâmetros\n",
    "out_channels = 128\n",
    "num_features = dataset.num_features\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Instancia o modelo - Graph Auto-Encoder (GAE)\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# otimizador e critério\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 26588], longitude=[4575], latitude=[4575], name=[4575], x=[4575, 895], edge_attr=[26588, 1], pos_edge_label=[13294], pos_edge_label_index=[2, 13294], neg_edge_label=[13294], neg_edge_label_index=[2, 13294])\n",
      "-----\n",
      "Data(edge_index=[2, 30386], longitude=[4575], latitude=[4575], name=[4575], x=[4575, 895], edge_attr=[30386, 1], pos_edge_label=[3798], pos_edge_label_index=[2, 3798], neg_edge_label=[3798], neg_edge_label_index=[2, 3798])\n",
      "\n",
      "Data(edge_index=[2, 26588], longitude=[4575], latitude=[4575], name=[4575], x=[4575, 895], edge_attr=[26588, 1], pos_edge_label=[13294], pos_edge_label_index=[2, 13294], neg_edge_label=[13294], neg_edge_label_index=[2, 13294])\n",
      "Data(edge_index=[2, 26588], longitude=[4575], latitude=[4575], name=[4575], x=[4575, 895], edge_attr=[26588, 1], pos_edge_label=[1899], pos_edge_label_index=[2, 1899], neg_edge_label=[1899], neg_edge_label_index=[2, 1899])\n"
     ]
    }
   ],
   "source": [
    "dataset.train_mask = None\n",
    "dataset.val_mask = None\n",
    "dataset.test_mask = None\n",
    "\n",
    "# Usando add_negative_train_samples=True para adicionar exemplos negativos (exemplos onde nao tem link)\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.RandomLinkSplit(is_undirected=True, add_negative_train_samples=True, split_labels=True),\n",
    "])\n",
    "\n",
    "# Usar esse caso queira negativos mas com valores fixos de teste\n",
    "# transform = T.Compose([\n",
    "#     T.NormalizeFeatures(),\n",
    "#     T.RandomLinkSplit(num_val=0.10, num_test=0.10, neg_sampling_ratio = 1.0,\n",
    "#                   add_negative_train_samples=True, is_undirected=True, split_labels=True),\n",
    "# ])\n",
    "\n",
    "# Usar esse caso nao queira negativos\n",
    "# transform = T.Compose([\n",
    "#     T.NormalizeFeatures(),\n",
    "#     T.RandomLinkSplit(num_val=0.10, num_test=0.10, neg_sampling_ratio = 1.0,\n",
    "#                   is_undirected=True, split_labels=True),\n",
    "# ])\n",
    "\n",
    "train_data, val_data, test_data = transform(dataset)\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "print(train_data)\n",
    "print('-----')\n",
    "print(test_data)\n",
    "print()\n",
    "print(train_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 1, Perda: 0.7287930250167847, AUC: 0.85856098980617, AP: 0.8681677631587922\n",
      "Época: 2, Perda: 0.7272034883499146, AUC: 0.8589632136422789, AP: 0.8687165944036637\n",
      "Época: 3, Perda: 0.7260039448738098, AUC: 0.8586518055981904, AP: 0.8689394869403557\n",
      "Época: 4, Perda: 0.7252641916275024, AUC: 0.8560071942745288, AP: 0.8682272972283761\n",
      "Época: 5, Perda: 0.7247818112373352, AUC: 0.847363887925271, AP: 0.864861781212596\n",
      "Época: 6, Perda: 0.7244954109191895, AUC: 0.8332683064532455, AP: 0.8572163360839347\n",
      "Época: 7, Perda: 0.7243427038192749, AUC: 0.810529418631962, AP: 0.838751642106423\n",
      "Época: 8, Perda: 0.724311888217926, AUC: 0.7819030331365334, AP: 0.8083266730320153\n",
      "Época: 9, Perda: 0.7243171334266663, AUC: 0.7572186076150498, AP: 0.7769839709595946\n",
      "Época: 10, Perda: 0.7243549227714539, AUC: 0.7419690416590756, AP: 0.7550283920188957\n",
      "Época: 11, Perda: 0.7243688106536865, AUC: 0.7352345307430173, AP: 0.7444079328588403\n",
      "Época: 12, Perda: 0.7243887782096863, AUC: 0.7340921928644577, AP: 0.7426530020822424\n",
      "Época: 13, Perda: 0.7243751287460327, AUC: 0.736542139498048, AP: 0.746755604119173\n",
      "Época: 14, Perda: 0.7243512272834778, AUC: 0.7406962340701475, AP: 0.7544097155708054\n",
      "Época: 15, Perda: 0.7243267893791199, AUC: 0.7464905589011815, AP: 0.7651077305952954\n",
      "Época: 16, Perda: 0.7242940068244934, AUC: 0.7537633093662832, AP: 0.7772620083240256\n",
      "Época: 17, Perda: 0.724267840385437, AUC: 0.7608692638042084, AP: 0.7884266395997386\n",
      "Época: 18, Perda: 0.7242318987846375, AUC: 0.7681748743345144, AP: 0.7991216091508446\n",
      "Época: 19, Perda: 0.7242125272750854, AUC: 0.7754850603169374, AP: 0.8088379958534129\n",
      "Época: 20, Perda: 0.7241913080215454, AUC: 0.7816136704526454, AP: 0.8164674082417045\n",
      "Época: 21, Perda: 0.7241635322570801, AUC: 0.7870771762306095, AP: 0.8227570815744226\n",
      "Época: 22, Perda: 0.7241491079330444, AUC: 0.7919112107173172, AP: 0.8279846727938279\n",
      "Época: 23, Perda: 0.724144697189331, AUC: 0.7955930631709103, AP: 0.831808016455403\n",
      "Época: 24, Perda: 0.7241315841674805, AUC: 0.7983935171666805, AP: 0.8345906906857448\n",
      "Época: 25, Perda: 0.7241271138191223, AUC: 0.8006515721114824, AP: 0.8367517688517749\n",
      "Época: 26, Perda: 0.7241243720054626, AUC: 0.8021983522271776, AP: 0.8382138485913484\n",
      "Época: 27, Perda: 0.7241116762161255, AUC: 0.8030696292303174, AP: 0.8390826602437456\n",
      "Época: 28, Perda: 0.7241129279136658, AUC: 0.8032855073802042, AP: 0.839417187465999\n",
      "Época: 29, Perda: 0.724100649356842, AUC: 0.8031347947604696, AP: 0.8394404011366763\n",
      "Época: 30, Perda: 0.7241034507751465, AUC: 0.8025617540453236, AP: 0.8391126198726604\n",
      "Época: 31, Perda: 0.7241019010543823, AUC: 0.8015803888912458, AP: 0.8384657928710977\n",
      "Época: 32, Perda: 0.724098265171051, AUC: 0.8000344406759357, AP: 0.8374032735252938\n",
      "Época: 33, Perda: 0.7240976691246033, AUC: 0.7977040103976456, AP: 0.8357381384211062\n",
      "Época: 34, Perda: 0.7240971922874451, AUC: 0.7948324289189649, AP: 0.8336430975259894\n",
      "Época: 35, Perda: 0.7240936756134033, AUC: 0.7916107560282968, AP: 0.8312090750434709\n",
      "Época: 36, Perda: 0.7240903973579407, AUC: 0.788107207557205, AP: 0.8284945155586563\n",
      "Época: 37, Perda: 0.7240882515907288, AUC: 0.7846207130440038, AP: 0.8257758994370303\n",
      "Época: 38, Perda: 0.7240844964981079, AUC: 0.781338588725365, AP: 0.8231893743161919\n",
      "Época: 39, Perda: 0.7240885496139526, AUC: 0.778168493658562, AP: 0.8206574800982172\n",
      "Época: 40, Perda: 0.7240864038467407, AUC: 0.7751327505039237, AP: 0.8182048207259043\n",
      "Época: 41, Perda: 0.7240806221961975, AUC: 0.7721510808743051, AP: 0.8157796435665374\n",
      "Época: 42, Perda: 0.7240877151489258, AUC: 0.7696165577015812, AP: 0.8137353709725594\n",
      "Época: 43, Perda: 0.7240797877311707, AUC: 0.7676474494904748, AP: 0.812176180253359\n",
      "Época: 44, Perda: 0.7240826487541199, AUC: 0.7659986229275628, AP: 0.8108162239438008\n",
      "Época: 45, Perda: 0.7240838408470154, AUC: 0.7643775263774814, AP: 0.8094704011613969\n",
      "Época: 46, Perda: 0.7240838408470154, AUC: 0.7631586536635091, AP: 0.8084850652728885\n",
      "Época: 47, Perda: 0.724082887172699, AUC: 0.7620609611056066, AP: 0.8075994850247463\n",
      "Época: 48, Perda: 0.7240818738937378, AUC: 0.7611931503540708, AP: 0.8068886576787722\n",
      "Época: 49, Perda: 0.7240785360336304, AUC: 0.7599278298686067, AP: 0.8058439275715421\n",
      "Época: 50, Perda: 0.7240824103355408, AUC: 0.7588844881358527, AP: 0.8050012890115262\n",
      "Época: 51, Perda: 0.7240778803825378, AUC: 0.7575290451086891, AP: 0.8038478504294434\n",
      "Época: 52, Perda: 0.7240744233131409, AUC: 0.7562397381621269, AP: 0.8027505103324306\n",
      "Época: 53, Perda: 0.7240784764289856, AUC: 0.755017815146743, AP: 0.8016702880780018\n",
      "Época: 54, Perda: 0.7240803241729736, AUC: 0.7536837242294592, AP: 0.8004895318258698\n",
      "Época: 55, Perda: 0.724077582359314, AUC: 0.752440726404324, AP: 0.7993808128412807\n",
      "Época: 56, Perda: 0.7240778803825378, AUC: 0.7520433553204605, AP: 0.7990418820431204\n",
      "Época: 57, Perda: 0.7240832448005676, AUC: 0.7515998137652339, AP: 0.7986491076866375\n",
      "Época: 58, Perda: 0.7240787744522095, AUC: 0.751604389217351, AP: 0.7986662711420567\n",
      "Época: 59, Perda: 0.7240749001502991, AUC: 0.7516658111957708, AP: 0.7987479367510752\n",
      "Época: 60, Perda: 0.7240740656852722, AUC: 0.7524046773876443, AP: 0.79946817141278\n",
      "Época: 61, Perda: 0.7240793108940125, AUC: 0.7530179266213946, AP: 0.800030088575514\n",
      "Época: 62, Perda: 0.7240797281265259, AUC: 0.7527906791662472, AP: 0.7998428445452456\n",
      "Época: 63, Perda: 0.7240721583366394, AUC: 0.7523433940592883, AP: 0.7994444349616062\n",
      "Época: 64, Perda: 0.7240789532661438, AUC: 0.7518538206827629, AP: 0.799001692987398\n",
      "Época: 65, Perda: 0.7240732908248901, AUC: 0.7517743741960029, AP: 0.7989172677635503\n",
      "Época: 66, Perda: 0.7240740656852722, AUC: 0.7520873073907972, AP: 0.7992122754539515\n",
      "Época: 67, Perda: 0.7240784168243408, AUC: 0.7523903964310363, AP: 0.7994892967040057\n",
      "Época: 68, Perda: 0.7240754961967468, AUC: 0.7529534543415632, AP: 0.799997255337456\n",
      "Época: 69, Perda: 0.7240752577781677, AUC: 0.7540322904907408, AP: 0.8009844432038277\n",
      "Época: 70, Perda: 0.724074125289917, AUC: 0.7546395777717326, AP: 0.8015279640422666\n",
      "Época: 71, Perda: 0.7240750193595886, AUC: 0.7550939340319632, AP: 0.801931687434621\n",
      "Época: 72, Perda: 0.7240738868713379, AUC: 0.7558139438151119, AP: 0.8025830600273732\n",
      "Época: 73, Perda: 0.7240742444992065, AUC: 0.7569246694790446, AP: 0.8035870054161877\n",
      "Época: 74, Perda: 0.7240772247314453, AUC: 0.757894110727605, AP: 0.8044664141312321\n",
      "Época: 75, Perda: 0.7240778207778931, AUC: 0.758328778678726, AP: 0.804858610852758\n",
      "Época: 76, Perda: 0.7240749001502991, AUC: 0.7588154404039043, AP: 0.8053054435221143\n",
      "Época: 77, Perda: 0.7240762114524841, AUC: 0.7586636185836564, AP: 0.8051751503233872\n",
      "Época: 78, Perda: 0.7240771055221558, AUC: 0.7586489216768562, AP: 0.8051774381587553\n",
      "Época: 79, Perda: 0.7240734696388245, AUC: 0.7585691978899678, AP: 0.8051276359404869\n",
      "Época: 80, Perda: 0.7240775227546692, AUC: 0.7588796353836074, AP: 0.8054282197355154\n",
      "Época: 81, Perda: 0.7240758538246155, AUC: 0.7588096171012098, AP: 0.8053916241475343\n",
      "Época: 82, Perda: 0.724077045917511, AUC: 0.7587003608506571, AP: 0.8053101372747147\n",
      "Época: 83, Perda: 0.7240733504295349, AUC: 0.7582358831357432, AP: 0.8048910573086471\n",
      "Época: 84, Perda: 0.7240736484527588, AUC: 0.758058688353755, AP: 0.8047447770055334\n",
      "Época: 85, Perda: 0.7240766286849976, AUC: 0.7577604520657613, AP: 0.8044789190507803\n",
      "Época: 86, Perda: 0.7240782380104065, AUC: 0.7572241536176159, AP: 0.8040044946431425\n",
      "Época: 87, Perda: 0.7240715622901917, AUC: 0.7573124737084815, AP: 0.804096659253092\n",
      "Época: 88, Perda: 0.7240781188011169, AUC: 0.7578648555640688, AP: 0.8045980469996528\n",
      "Época: 89, Perda: 0.7240679264068604, AUC: 0.7588073987001833, AP: 0.8054594597724417\n",
      "Época: 90, Perda: 0.7240728139877319, AUC: 0.7597815540509252, AP: 0.806347265355277\n",
      "Época: 91, Perda: 0.7240728139877319, AUC: 0.7603196549499043, AP: 0.8068366008585117\n",
      "Época: 92, Perda: 0.7240753769874573, AUC: 0.7603433641108746, AP: 0.806863062594334\n",
      "Época: 93, Perda: 0.7240734696388245, AUC: 0.7601932060913964, AP: 0.8067299346007157\n",
      "Época: 94, Perda: 0.724078357219696, AUC: 0.7595017582214636, AP: 0.8061134134862558\n",
      "Época: 95, Perda: 0.7240719795227051, AUC: 0.7589485444654915, AP: 0.805617936549881\n",
      "Época: 96, Perda: 0.7240758538246155, AUC: 0.7583445847860394, AP: 0.8050689859551022\n",
      "Época: 97, Perda: 0.7240772843360901, AUC: 0.7581990022186783, AP: 0.8049464220390787\n",
      "Época: 98, Perda: 0.724071204662323, AUC: 0.7587889582416509, AP: 0.8054841046189328\n",
      "Época: 99, Perda: 0.7240728139877319, AUC: 0.759398325273605, AP: 0.8060545419592475\n",
      "Época: 100, Perda: 0.7240734100341797, AUC: 0.7597407909320639, AP: 0.8063682360489921\n",
      "Area Under the Curve: 0.7590825844150119, AP: 0.8088793007297342\n"
     ]
    }
   ],
   "source": [
    "x = train_data.x.to(device).to(torch.float)\n",
    "train_pos_edge_index = train_data.pos_edge_label_index.to(device)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "\n",
    "    # *** Nova rodada de amostragem negativa para cada época de treinamento (tirar junto com o negativo do random split se piorar):\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.neg_edge_label_index.size(1))\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.neg_edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.pos_edge_label,\n",
    "        train_data.pos_edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    # ***\n",
    "\n",
    "    # Usar esse caso nao queira negativos\n",
    "    # loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return float(loss)\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "        out = model.decode(z, train_pos_edge_index)\n",
    "        return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "# Treino\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "    print('Época: {:}, Perda: {:}, AUC: {:}, AP: {:}'.format(epoch, loss, auc, ap))   \n",
    "\n",
    "# Teste\n",
    "auc, ap = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "print('Area Under the Curve: {:}, AP: {:}'.format( auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodificação do teste expandida\n",
    "temp_positivos = model.decode(test_data.x, test_data.pos_edge_label_index)\n",
    "temp_negativos = model.decode(test_data.x, test_data.neg_edge_label_index)\n",
    "\n",
    "# resultados\n",
    "results = torch.cat([temp_positivos, temp_negativos]).cpu()\n",
    "labels = torch.cat([test_data.pos_edge_label, test_data.neg_edge_label]).cpu()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels, results)\n",
    "f1_scores = 2*recall*precision/(recall+precision)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "threshold = best_threshold\n",
    "\n",
    "evaluation_edges_u = []\n",
    "evaluation_edges_v = []\n",
    "for _, linkID, u, v in edges_to_evaluate.to_records():\n",
    "    u_idx = key_to_index[u]\n",
    "    v_idx = key_to_index[v]\n",
    "    evaluation_edges_u.append(key_to_index[u])\n",
    "    evaluation_edges_v.append(key_to_index[v])\n",
    "\n",
    "edges_to_evaluate_tensor = torch.tensor([evaluation_edges_u, evaluation_edges_v])\n",
    "\n",
    "# decoder\n",
    "temp = model.decode(test_data.x, edges_to_evaluate_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribui 0 ou 1 de acordo com o threshold\n",
    "resultados = (temp > threshold).int()\n",
    "# detach pra cpu pra poder usar o pandas\n",
    "resultados = resultados.cpu().detach()\n",
    "\n",
    "concatenados = pd.concat([edges_to_evaluate, pd.Series(resultados, name='link')], axis=1)\n",
    "links = concatenados[['linkID', 'link']]\n",
    "links.to_csv('results_gae_teste5.csv', columns=['linkID', 'link'],index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}