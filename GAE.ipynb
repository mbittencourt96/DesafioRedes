{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os grafos e csv necessários e bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import random\n",
    "from torch_geometric.nn import GAE, GCNConv\n",
    "import torch.nn as nn\n",
    "from torch import nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch.optim as optim\n",
    "import torch \n",
    "from torch_geometric import seed_everything\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "G = nx.read_gml('GraphMissingEdges.gml')\n",
    "\n",
    "edges_to_evaluate = pd.read_csv('edgesToEvaluate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(69)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "categories = pd.read_csv('categories.csv', index_col='CategoryId')\n",
    "num_categorias = len(categories)\n",
    "\n",
    "def bag_of_words(categories_list):\n",
    "    # print(categories_list)\n",
    "    categorias = categories_list.split(',')\n",
    "    bag = np.zeros(num_categorias, dtype=np.float32)\n",
    "\n",
    "    for i, categoria in enumerate(categorias):\n",
    "        try:\n",
    "            bag[i] = 1\n",
    "        except IndexError:\n",
    "            pass\n",
    "    return bag\n",
    "\n",
    "G_pyg = G.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o dataset a partir do grafo do desafio\n",
    "# Aqui definimos os parametros que serão relevantes (rating, reviewCount e categories)\n",
    "\n",
    "key_to_index = {}\n",
    "for index, (n, data) in enumerate(G_pyg.nodes.data()):\n",
    "    key_to_index[n] = index\n",
    "    G_pyg.nodes[n]['stars'] = np.array([float(data['stars'])])\n",
    "    G_pyg.nodes[n]['reviewCount'] = np.array([float(data['reviewCount'])])\n",
    "    G_pyg.nodes[n]['categories'] = bag_of_words(data['categories'])\n",
    "\n",
    "dataset = from_networkx(G_pyg, group_edge_attrs=all,group_node_attrs=['categories','reviewCount','stars'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da GAE de duas camadas, ativação com Relu na GCN, otimizador Adam, learning rate = 0.001 e 100 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index - representa a conectividade do grafo no formato [2, num_edges]\n",
    "# edge_attr - matriz de features de aresta com o formato [num_edges, num_edges_features]\n",
    "\n",
    "# parâmetros\n",
    "out_channels = 128\n",
    "num_features = dataset.num_features\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Instancia o modelo - Graph Auto-Encoder (GAE)\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "model = model.to(device)\n",
    "\n",
    "# otimizador e critério\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 30386], longitude=[4575], latitude=[4575], name=[4575], x=[4575, 895], edge_attr=[30386, 1], pos_edge_label=[15193], pos_edge_label_index=[2, 15193], neg_edge_label=[15193], neg_edge_label_index=[2, 15193])\n",
      "-----\n",
      "Data(edge_index=[2, 34184], longitude=[4575], latitude=[4575], name=[4575], x=[4575, 895], edge_attr=[34184, 1], pos_edge_label=[1899], pos_edge_label_index=[2, 1899], neg_edge_label=[1899], neg_edge_label_index=[2, 1899])\n",
      "\n",
      "Data(edge_index=[2, 30386], longitude=[4575], latitude=[4575], name=[4575], x=[4575, 895], edge_attr=[30386, 1], pos_edge_label=[15193], pos_edge_label_index=[2, 15193], neg_edge_label=[15193], neg_edge_label_index=[2, 15193])\n",
      "Data(edge_index=[2, 30386], longitude=[4575], latitude=[4575], name=[4575], x=[4575, 895], edge_attr=[30386, 1], pos_edge_label=[1899], pos_edge_label_index=[2, 1899], neg_edge_label=[1899], neg_edge_label_index=[2, 1899])\n"
     ]
    }
   ],
   "source": [
    "dataset.train_mask = None\n",
    "dataset.val_mask = None\n",
    "dataset.test_mask = None\n",
    "\n",
    "# Usando add_negative_train_samples=True para adicionar exemplos negativos (exemplos onde nao tem link)\n",
    "# transform = T.Compose([\n",
    "#     T.NormalizeFeatures(),\n",
    "#     T.RandomLinkSplit(is_undirected=True, add_negative_train_samples=True, split_labels=True),\n",
    "# ])\n",
    "\n",
    "# Usar esse caso queira negativos mas com valores fixos de teste\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.RandomLinkSplit(num_val=0.10, num_test=0.10, neg_sampling_ratio = 1.0,\n",
    "                  add_negative_train_samples=True, is_undirected=True, split_labels=True),\n",
    "])\n",
    "\n",
    "# Usar esse caso nao queira negativos\n",
    "# transform = T.Compose([\n",
    "#     T.NormalizeFeatures(),\n",
    "#     T.RandomLinkSplit(num_val=0.10, num_test=0.10, neg_sampling_ratio = 1.0,\n",
    "#                   is_undirected=True, split_labels=True),\n",
    "# ])\n",
    "\n",
    "train_data, val_data, test_data = transform(dataset)\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "print(train_data)\n",
    "print('-----')\n",
    "print(test_data)\n",
    "print()\n",
    "print(train_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época: 1, Perda: 0.7290575504302979, AUC: 0.8646944526941232, AP: 0.8757435739540872\n",
      "Época: 2, Perda: 0.7273792028427124, AUC: 0.8648175739510915, AP: 0.8759985473417987\n",
      "Época: 3, Perda: 0.7261332869529724, AUC: 0.8639371460437175, AP: 0.8757667509468937\n",
      "Época: 4, Perda: 0.7253693342208862, AUC: 0.8605461814247182, AP: 0.874572272795964\n",
      "Época: 5, Perda: 0.7248110771179199, AUC: 0.8535354795808665, AP: 0.871579754387368\n",
      "Época: 6, Perda: 0.7245157957077026, AUC: 0.8389304977731413, AP: 0.8636827154012726\n",
      "Época: 7, Perda: 0.7243630886077881, AUC: 0.8162090798599413, AP: 0.8475957531773715\n",
      "Época: 8, Perda: 0.7243187427520752, AUC: 0.7902188480342609, AP: 0.8234594142715432\n",
      "Época: 9, Perda: 0.7243309020996094, AUC: 0.7681476989219402, AP: 0.797311725548772\n",
      "Época: 10, Perda: 0.7243563532829285, AUC: 0.7541468154437315, AP: 0.777159218855692\n",
      "Época: 11, Perda: 0.7243836522102356, AUC: 0.747638026832115, AP: 0.7665375492403013\n",
      "Época: 12, Perda: 0.7243944406509399, AUC: 0.7458796667185217, AP: 0.7637433777288183\n",
      "Época: 13, Perda: 0.7243838310241699, AUC: 0.7469505998140425, AP: 0.7663063807872311\n",
      "Época: 14, Perda: 0.7243667840957642, AUC: 0.7500559453008859, AP: 0.7729813890714687\n",
      "Época: 15, Perda: 0.7243483066558838, AUC: 0.7535432717144719, AP: 0.7806778938203558\n",
      "Época: 16, Perda: 0.7243067622184753, AUC: 0.7590974546343923, AP: 0.7907250693446659\n",
      "Época: 17, Perda: 0.7242767214775085, AUC: 0.7652562904840855, AP: 0.8005691428388488\n",
      "Época: 18, Perda: 0.7242471575737, AUC: 0.7709456572165556, AP: 0.8088994172378479\n",
      "Época: 19, Perda: 0.7242119908332825, AUC: 0.776864073855007, AP: 0.816540243370844\n",
      "Época: 20, Perda: 0.7241988182067871, AUC: 0.782236209240694, AP: 0.8228259176294801\n",
      "Época: 21, Perda: 0.7241742014884949, AUC: 0.7869744365330719, AP: 0.8279635955425918\n",
      "Época: 22, Perda: 0.7241613864898682, AUC: 0.7910808354831026, AP: 0.8322452418014472\n",
      "Época: 23, Perda: 0.7241489291191101, AUC: 0.7940724879173402, AP: 0.8352028229320452\n",
      "Época: 24, Perda: 0.7241353392601013, AUC: 0.7961799688924717, AP: 0.8373078351327997\n",
      "Época: 25, Perda: 0.7241249680519104, AUC: 0.7978138212484551, AP: 0.8389100021740116\n",
      "Época: 26, Perda: 0.7241194844245911, AUC: 0.7990870447875756, AP: 0.840174928642019\n",
      "Época: 27, Perda: 0.7241165041923523, AUC: 0.7998540569424722, AP: 0.8409688183073636\n",
      "Época: 28, Perda: 0.7241097092628479, AUC: 0.8001958293506102, AP: 0.8414040700321581\n",
      "Época: 29, Perda: 0.7241044044494629, AUC: 0.8000424823796566, AP: 0.8414529402155879\n",
      "Época: 30, Perda: 0.7241050004959106, AUC: 0.7993977595813434, AP: 0.8411238717590606\n",
      "Época: 31, Perda: 0.7241008281707764, AUC: 0.7983106044283166, AP: 0.8404624766613167\n",
      "Época: 32, Perda: 0.724097728729248, AUC: 0.7969695810078251, AP: 0.8396000748888358\n",
      "Época: 33, Perda: 0.7240918874740601, AUC: 0.7954667529624666, AP: 0.8386171296592577\n",
      "Época: 34, Perda: 0.7240968346595764, AUC: 0.7935737636365805, AP: 0.8373273059945023\n",
      "Época: 35, Perda: 0.7240960597991943, AUC: 0.7911188256006807, AP: 0.8355926818291821\n",
      "Época: 36, Perda: 0.7240892052650452, AUC: 0.7881978846991612, AP: 0.8334244357291687\n",
      "Época: 37, Perda: 0.7240927219390869, AUC: 0.7850481711917887, AP: 0.8310610859747427\n",
      "Época: 38, Perda: 0.7240878939628601, AUC: 0.7818448001095891, AP: 0.8286624616453797\n",
      "Época: 39, Perda: 0.7240878939628601, AUC: 0.7783825693576149, AP: 0.8260224103679887\n",
      "Época: 40, Perda: 0.7240921854972839, AUC: 0.7748321571648391, AP: 0.823303637384774\n",
      "Época: 41, Perda: 0.7240864038467407, AUC: 0.7715923211157669, AP: 0.8207975831602408\n",
      "Época: 42, Perda: 0.7240862846374512, AUC: 0.7686784513675196, AP: 0.81856164894444\n",
      "Época: 43, Perda: 0.7240829467773438, AUC: 0.7659957112762156, AP: 0.8164945273106151\n",
      "Época: 44, Perda: 0.7240841388702393, AUC: 0.7637968599088071, AP: 0.8148248141987537\n",
      "Época: 45, Perda: 0.7240801453590393, AUC: 0.7618425872545652, AP: 0.8133292538951475\n",
      "Época: 46, Perda: 0.7240795493125916, AUC: 0.7601337252138746, AP: 0.812016236673375\n",
      "Época: 47, Perda: 0.7240820527076721, AUC: 0.7583318289801373, AP: 0.8105597779631086\n",
      "Época: 48, Perda: 0.7240788340568542, AUC: 0.7567618943037285, AP: 0.8093301001192384\n",
      "Época: 49, Perda: 0.7240813374519348, AUC: 0.7554497100965809, AP: 0.8083340379664122\n",
      "Época: 50, Perda: 0.7240855693817139, AUC: 0.7537315585015921, AP: 0.8069262308770477\n",
      "Época: 51, Perda: 0.7240778207778931, AUC: 0.7527115099796157, AP: 0.8061280840242467\n",
      "Época: 52, Perda: 0.7240754961967468, AUC: 0.7518045999099884, AP: 0.8054088913504053\n",
      "Época: 53, Perda: 0.724078893661499, AUC: 0.7506615687811079, AP: 0.8044652279747897\n",
      "Época: 54, Perda: 0.7240803837776184, AUC: 0.7491982560040331, AP: 0.8032345861092617\n",
      "Época: 55, Perda: 0.7240756154060364, AUC: 0.7477277334236223, AP: 0.8020215396916233\n",
      "Época: 56, Perda: 0.7240785360336304, AUC: 0.7466434899219427, AP: 0.8011177581163557\n",
      "Época: 57, Perda: 0.7240739464759827, AUC: 0.7462534672914793, AP: 0.8007817915037585\n",
      "Época: 58, Perda: 0.7240746021270752, AUC: 0.7468134749005948, AP: 0.8012491926144201\n",
      "Época: 59, Perda: 0.7240802645683289, AUC: 0.7474964651166145, AP: 0.8018436262874354\n",
      "Época: 60, Perda: 0.7240723371505737, AUC: 0.7486479538994082, AP: 0.8028239192537114\n",
      "Época: 61, Perda: 0.7240764498710632, AUC: 0.7495038407454271, AP: 0.8035529797267491\n",
      "Época: 62, Perda: 0.7240772247314453, AUC: 0.7501230519319362, AP: 0.8040925137238761\n",
      "Época: 63, Perda: 0.7240767478942871, AUC: 0.7509146051481876, AP: 0.8047742707714116\n",
      "Época: 64, Perda: 0.7240725755691528, AUC: 0.752045573721487, AP: 0.8057310486257392\n",
      "Época: 65, Perda: 0.7240761518478394, AUC: 0.7532462832770552, AP: 0.8067285925683292\n",
      "Época: 66, Perda: 0.7240758538246155, AUC: 0.7540415800450391, AP: 0.8073889918645392\n",
      "Época: 67, Perda: 0.7240751385688782, AUC: 0.7549181257506168, AP: 0.8081093549465972\n",
      "Época: 68, Perda: 0.7240744233131409, AUC: 0.7557353292287369, AP: 0.808769933559206\n",
      "Época: 69, Perda: 0.7240749597549438, AUC: 0.7563169662478604, AP: 0.8092379929489792\n",
      "Época: 70, Perda: 0.7240760922431946, AUC: 0.7571228004207198, AP: 0.8099162747517323\n",
      "Época: 71, Perda: 0.72407466173172, AUC: 0.7575764634306296, AP: 0.8102907814802183\n",
      "Época: 72, Perda: 0.7240747809410095, AUC: 0.757866103414646, AP: 0.810522618406156\n",
      "Época: 73, Perda: 0.724072277545929, AUC: 0.7581248244343562, AP: 0.8107093104441249\n",
      "Época: 74, Perda: 0.7240771055221558, AUC: 0.7580679779080532, AP: 0.8106494188020545\n",
      "Época: 75, Perda: 0.7240743041038513, AUC: 0.7581440967932735, AP: 0.8106997861391151\n",
      "Época: 76, Perda: 0.7240742444992065, AUC: 0.7578482175563703, AP: 0.8104354551760813\n",
      "Época: 77, Perda: 0.7240772247314453, AUC: 0.7579693977124403, AP: 0.8105435350737763\n",
      "Época: 78, Perda: 0.7240704894065857, AUC: 0.7581016698736426, AP: 0.8106563492961152\n",
      "Época: 79, Perda: 0.7240695953369141, AUC: 0.758797138595436, AP: 0.8112544016183352\n",
      "Época: 80, Perda: 0.724077045917511, AUC: 0.7589556156187633, AP: 0.8114010135913057\n",
      "Época: 81, Perda: 0.724067211151123, AUC: 0.7589649051730616, AP: 0.8114077644500517\n",
      "Época: 82, Perda: 0.7240772843360901, AUC: 0.7588666022775769, AP: 0.8113206127699373\n",
      "Época: 83, Perda: 0.7240724563598633, AUC: 0.7581820869108515, AP: 0.8107341785908717\n",
      "Época: 84, Perda: 0.7240737676620483, AUC: 0.7573467202743276, AP: 0.8100238762850656\n",
      "Época: 85, Perda: 0.7240791916847229, AUC: 0.7564809892737537, AP: 0.8092882283609034\n",
      "Época: 86, Perda: 0.724070131778717, AUC: 0.7563092018442678, AP: 0.8091342978076284\n",
      "Época: 87, Perda: 0.7240754961967468, AUC: 0.7564969340311314, AP: 0.8092851055520709\n",
      "Época: 88, Perda: 0.724071204662323, AUC: 0.7567473360469924, AP: 0.8095005345488778\n",
      "Época: 89, Perda: 0.7240698337554932, AUC: 0.7576613172698915, AP: 0.8102792148901334\n",
      "Época: 90, Perda: 0.7240787148475647, AUC: 0.7579293278438999, AP: 0.8105142833849106\n",
      "Época: 91, Perda: 0.7240724563598633, AUC: 0.7575716106783843, AP: 0.8101903906421906\n",
      "Época: 92, Perda: 0.7240753769874573, AUC: 0.7566280969918204, AP: 0.809355415772254\n",
      "Época: 93, Perda: 0.7240653038024902, AUC: 0.7561521113215818, AP: 0.8089342207638186\n",
      "Época: 94, Perda: 0.7240714430809021, AUC: 0.7560660096317425, AP: 0.808832414657258\n",
      "Época: 95, Perda: 0.7240727543830872, AUC: 0.7557473917843182, AP: 0.8085238816959813\n",
      "Época: 96, Perda: 0.724077045917511, AUC: 0.7555227786803898, AP: 0.8082939422690425\n",
      "Época: 97, Perda: 0.7240704894065857, AUC: 0.7560424391208367, AP: 0.808705461940691\n",
      "Época: 98, Perda: 0.7240755558013916, AUC: 0.7560450734720555, AP: 0.8086718109928576\n",
      "Época: 99, Perda: 0.7240757346153259, AUC: 0.7559679840363862, AP: 0.8085777583391671\n",
      "Época: 100, Perda: 0.7240807414054871, AUC: 0.7551186137433826, AP: 0.8078178316507174\n",
      "Area Under the Curve: 0.759128928198955, AP: 0.8066836691458263\n"
     ]
    }
   ],
   "source": [
    "x = train_data.x.to(device).to(torch.float)\n",
    "train_pos_edge_index = train_data.pos_edge_label_index.to(device)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "\n",
    "    # *** Nova rodada de amostragem negativa para cada época de treinamento (tirar junto com o negativo do random split se piorar):\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.neg_edge_label_index.size(1))\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.neg_edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.pos_edge_label,\n",
    "        train_data.pos_edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    # ***\n",
    "\n",
    "    # Usar esse caso nao queira negativos\n",
    "    # loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return float(loss)\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "        out = model.decode(z, train_pos_edge_index)\n",
    "        return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "# Treino\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "    print('Época: {:}, Perda: {:}, AUC: {:}, AP: {:}'.format(epoch, loss, auc, ap))   \n",
    "\n",
    "# Teste\n",
    "auc, ap = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "print('Area Under the Curve: {:}, AP: {:}'.format( auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodificação do teste expandida\n",
    "temp_positivos = model.decode(test_data.x, test_data.pos_edge_label_index)\n",
    "temp_negativos = model.decode(test_data.x, test_data.neg_edge_label_index)\n",
    "\n",
    "# resultados\n",
    "results = torch.cat([temp_positivos, temp_negativos]).cpu()\n",
    "labels = torch.cat([test_data.pos_edge_label, test_data.neg_edge_label]).cpu()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels, results)\n",
    "f1_scores = 2*recall*precision/(recall+precision)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "threshold = best_threshold\n",
    "\n",
    "evaluation_edges_u = []\n",
    "evaluation_edges_v = []\n",
    "for _, linkID, u, v in edges_to_evaluate.to_records():\n",
    "    u_idx = key_to_index[u]\n",
    "    v_idx = key_to_index[v]\n",
    "    evaluation_edges_u.append(key_to_index[u])\n",
    "    evaluation_edges_v.append(key_to_index[v])\n",
    "\n",
    "edges_to_evaluate_tensor = torch.tensor([evaluation_edges_u, evaluation_edges_v])\n",
    "\n",
    "# decoder\n",
    "temp = model.decode(test_data.x, edges_to_evaluate_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribui 0 ou 1 de acordo com o threshold\n",
    "resultados = (temp > threshold).int()\n",
    "# detach pra cpu pra poder usar o pandas\n",
    "resultados = resultados.cpu().detach()\n",
    "\n",
    "concatenados = pd.concat([edges_to_evaluate, pd.Series(resultados, name='link')], axis=1)\n",
    "links = concatenados[['linkID', 'link']]\n",
    "links.to_csv('results_gae_teste4.csv', columns=['linkID', 'link'],index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}